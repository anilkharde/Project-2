{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train=r\"I:\\data scientist using python\\project1\\P1 Data\\Consumer_Complaints_train.csv\"\n",
    "cd=pd.read_csv(file_train)\n",
    "file_test=r\"I:\\data scientist using python\\project1\\P1 Data\\Consumer_Complaints_test_share.csv\"\n",
    "test=pd.read_csv(file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Col: Date received, Date sent to company\n",
    "for col in ['Date received','Date sent to company']:\n",
    "    cd[col]=pd.to_datetime(cd[col],infer_datetime_format=True)\n",
    "    test[col]=pd.to_datetime(test[col],infer_datetime_format=True)\n",
    "cd['day_diff']=pd.to_numeric((cd['Date sent to company']-cd['Date received'])/86400000000000)\n",
    "test['day_diff']=pd.to_numeric((test['Date sent to company']-test['Date received'])/86400000000000)\n",
    "\n",
    "for col in ['Date received','Date sent to company']:\n",
    "    del cd[col]\n",
    "    del test[col]\n",
    "\n",
    "#from datetime import datetime\n",
    "#date_format=\"%Y-%m-%d\"\n",
    "#cd['date_diff']=0\n",
    "#for i in range(0,cd.shape[0]):\n",
    " #   a = datetime.strptime(cd['Date sent to company'][i], date_format)\n",
    "  #  b = datetime.strptime(cd['Date received'][i], date_format)\n",
    "   # delta = a - b\n",
    "    #days=delta.days\n",
    "    #cd['date_diff'][i]=days\n",
    "#del cd['Date sent to company']\n",
    "#del cd['Date received']\n",
    "\n",
    "# Col: ZIP code\n",
    "del cd['ZIP code']\n",
    "del test['ZIP code']\n",
    "\n",
    "# product, sub-product\n",
    "k1=pd.get_dummies(cd['Product'],drop_first=True,prefix='Product')\n",
    "cd=pd.concat([cd,k1],axis=1)\n",
    "del cd['Product']\n",
    "\n",
    "k2=pd.get_dummies(test['Product'],drop_first=True,prefix='Product')\n",
    "test=pd.concat([test,k2],axis=1)\n",
    "del test['Product']\n",
    "\n",
    "cd['Sub-product']=np.where(cd['Sub-product'].isnull(),0,1)\n",
    "test['Sub-product']=np.where(test['Sub-product'].isnull(),0,1)\n",
    "\n",
    "# col: Issue,sub-issue\n",
    "freq=cd['Issue'].value_counts()\n",
    "k=freq.index[freq>=9000][:-1]\n",
    "for cat in k:\n",
    "    name='Issue_'+cat.replace(',','_').replace(' ','_')\n",
    "    cd[name]=(cd['Issue']==cat).astype('int')\n",
    "    test[name]=(test['Issue']==cat).astype('int')\n",
    "del cd['Issue']\n",
    "del test['Issue']\n",
    "\n",
    "cd['Sub-issue']=np.where(cd['Sub-issue'].isnull(),0,1)\n",
    "test['Sub-issue']=np.where(test['Sub-issue'].isnull(),0,1)\n",
    "del cd['Sub-issue'],test['Sub-issue']\n",
    "\n",
    "# Col: Consumer disputed\n",
    "cd['Consumer_disputed']=cd['Consumer disputed?'].map({'Yes':1,\n",
    "                                                    'No':0})\n",
    "del cd['Consumer disputed?']\n",
    "\n",
    "# Col: Timely Response\n",
    "cd['Timely_response']=cd['Timely response?'].map({'Yes':1,'No':0})\n",
    "test['Timely_response']=test['Timely response?'].map({'Yes':1,'No':0})\n",
    "\n",
    "del cd['Timely response?'],test['Timely response?']\n",
    "\n",
    "# Col: Complaint ID\n",
    "del cd['Complaint ID'], test['Complaint ID']\n",
    "# Col: Company\n",
    "freq=cd['Company'].value_counts()\n",
    "k=freq.index[freq>=10000][:-1]\n",
    "for cat in k:\n",
    "    name='Company_'+cat.replace(',','_').replace(' ','_')\n",
    "    cd[name]=(cd['Company']==cat).astype('int')\n",
    "    test[name]=(test['Company']==cat).astype('int')\n",
    "del cd['Company']\n",
    "del test['Company']\n",
    "\n",
    "# Col:Tags\n",
    "cd['Tags']=np.where(cd['Tags'].isnull(),0,1)\n",
    "test['Tags']=np.where(test['Tags'].isnull(),0,1)     \n",
    "\n",
    "# Col: State\n",
    "freq=cd['State'].value_counts()\n",
    "k=freq.index[freq>10000]\n",
    "for val in k:\n",
    "    name='State_'+val\n",
    "    cd[name]=(cd['State']==val).astype(int)\n",
    "    test[name]=(test['State']==val).astype(int)\n",
    "del cd['State'],test['State']\n",
    "\n",
    "# Col: Company public response\n",
    "k1=pd.get_dummies(cd['Company public response'],drop_first=True,prefix='Company_public_response')\n",
    "cd=pd.concat([cd,k1],axis=1)\n",
    "del cd['Company public response']\n",
    "\n",
    "k2=pd.get_dummies(test['Company public response'],drop_first=True,prefix='Company_public_response')\n",
    "test=pd.concat([test,k2],axis=1)\n",
    "del test['Company public response']\n",
    "\n",
    "# Col:Company response to consumer, Submitted via\n",
    "for i in ['Company response to consumer','Submitted via']:\n",
    "    name=i.replace(' ','_')\n",
    "    k1=pd.get_dummies(cd[i],drop_first=True,prefix=name)\n",
    "    cd=pd.concat([cd,k1],axis=1)\n",
    "\n",
    "    k2=pd.get_dummies(test[i],drop_first=True,prefix=name)\n",
    "    test=pd.concat([test,k2],axis=1)\n",
    "    \n",
    "    del test[i]\n",
    "    del cd[i]\n",
    "\n",
    "# Col: Consumer_consent_provided_\n",
    "freq=cd['Consumer consent provided?'].value_counts()\n",
    "k=freq.index\n",
    "for val in k:\n",
    "    name='Consumer_consent_provided_'+val.replace(' ','_')\n",
    "    cd[name]=(cd['Consumer consent provided?']==val).astype(int)\n",
    "    test[name]=(test['Consumer consent provided?']==val).astype(int)\n",
    "del cd['Consumer consent provided?'],test['Consumer consent provided?']\n",
    "\n",
    "# Col: Consumer_complaint_narrative\n",
    "cd['Consumer_complaint_narrative']=np.where(cd['Consumer complaint narrative'].isnull(),0,1)\n",
    "test['Consumer_complaint_narrative']=np.where(test['Consumer complaint narrative'].isnull(),0,1)\n",
    "\n",
    "del cd['Consumer complaint narrative'],test['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_train,cd_test=train_test_split(cd,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382736, 76)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95685, 76)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cd_train=cd_train.drop('Consumer_disputed',axis=1)\n",
    "y_cd_train=cd_train['Consumer_disputed']\n",
    "x_cd_test=cd_test.drop('Consumer_disputed',axis=1)\n",
    "y_cd_test=cd_test['Consumer_disputed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382736, 75)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg=LogisticRegression(class_weight='balanced')\n",
    "logreg.fit(x_cd_train,y_cd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6162343759859666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=logreg.predict_proba(x_cd_train)[:,1]\n",
    "roc_auc_score(y_cd_train,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6171930800188312"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=logreg.predict_proba(x_cd_test)[:,1]\n",
    "roc_auc_score(y_cd_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning Hyperparameter\n",
    "\n",
    "#iteration1\n",
    "C1=np.linspace(1,100,100)\n",
    "roc_auc=[]\n",
    "for alpha in C1:\n",
    "    logreg=LogisticRegression(class_weight='balanced',C=alpha)\n",
    "    logreg.fit(x_cd_train,y_cd_train)\n",
    "    p=logreg.predict_proba(x_cd_train)[:,1]\n",
    "    roc=roc_auc_score(y_cd_train,p)\n",
    "    roc_auc.append(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=C1[roc_auc==max(roc_auc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=15, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg=LogisticRegression(class_weight='balanced',C=15)\n",
    "logreg.fit(x_cd_train,y_cd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6171895367346574"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=logreg.predict_proba(x_cd_test)[:,1]\n",
    "roc_auc_score(y_cd_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix analysis\n",
    "KS_all=[]\n",
    "Fbeta=[]\n",
    "Accuracy=[]\n",
    "Precision=[]\n",
    "cutoffs=np.linspace(0.01,0.99,99)\n",
    "p=logreg.predict_proba(x_cd_train)[:,1]\n",
    "real=y_cd_train\n",
    "for cutoff in cutoffs:\n",
    "    predicted=(p>cutoff).astype(int)\n",
    "    \n",
    "    TP=((predicted==1) & (real==1)).sum()\n",
    "    TN=((predicted==0) & (real==0)).sum()\n",
    "    FP=((predicted==1) & (real==0)).sum()\n",
    "    FN=((predicted==0) & (real==1)).sum()\n",
    "    P=TP+FN\n",
    "    N=FP+TN\n",
    "    KS=(TP/P) - (FP/N)\n",
    "    prec= TP/(TP+FP)\n",
    "    Recall=TP/P\n",
    "    accu=(TP+TN)/(P+N)\n",
    "    B=5\n",
    "    Fb=((1+B*B)*prec* Recall)/(B*B*prec+Recall)\n",
    "    KS_all.append(KS)\n",
    "    Fbeta.append(Fb)\n",
    "    Accuracy.append(accu)\n",
    "    Precision.append(prec)\n",
    "print('Cutoff for max accuracy of ',max(Accuracy)*100,'% is ',max(cutoffs[Accuracy==max(Accuracy)]))\n",
    "print('Cutoff for max Precision of ',max(Precision)*100,'% is ',max(cutoffs[Precision==max(Precision)]))\n",
    "print('Cutoff for max Fbeta of ',max(Fbeta),' is ',max(cutoffs[Fbeta==max(Fbeta)]))\n",
    "print('Cutoff for max KS_all of ',max(KS_all),' is ',max(cutoffs[KS_all==max(KS_all)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=(logreg.predict_proba(x_cd_train)[:,1]>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_cd_train,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[p==max(p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "ROC AUC Score for decision tree is  0.61\n",
      "-------------------------------\n",
      "Accuracy Using Decision tree is  78.8 %\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "x_cd_train.reset_index(drop=True,inplace=True)\n",
    "y_cd_train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "x_cd_test.reset_index(drop=True,inplace=True)\n",
    "y_cd_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "dtree=tree.DecisionTreeClassifier(criterion=\"entropy\",max_leaf_nodes=20)\n",
    "dtree.fit(x_cd_train,y_cd_train)\n",
    "p=dtree.predict(x_cd_test)\n",
    "pb=dtree.predict_proba(x_cd_test)[:,1]\n",
    "print('-------------------------------')\n",
    "print('ROC AUC Score for decision tree is ',round(roc_auc_score(y_cd_test,pb),2))\n",
    "\n",
    "# Creating Tree\n",
    "#dotfile=open(\"tree_prediction_sales1.dot\",'w')\n",
    "\n",
    "#tree.export_graphviz(dtree,out_file=dotfile,\n",
    " #                   feature_names=x_train.columns,\n",
    "  #                  class_names=['0','1'],\n",
    "   #                 proportion=True)\n",
    "#dotfile.close()\n",
    "\n",
    "# plot tree in www.webgraphviz.com using dot file generated\n",
    "score=accuracy_score(y_cd_test,p)\n",
    "print('-------------------------------')\n",
    "print('Accuracy Using Decision tree is ', round(score*100,2),'%')\n",
    "print('-------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   36.8s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   51.5s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.4s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   57.7s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   25.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    8.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   17.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.9min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   19.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   18.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   11.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   21.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:   17.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   39.4s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   38.7s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   41.8s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   16.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   20.5s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.643 (std: 0.002)\n",
      "Parameters: {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 15, 'max_features': 10, 'max_depth': 30, 'criterion': 'gini', 'bootstrap': False}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.642 (std: 0.001)\n",
      "Parameters: {'n_estimators': 500, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 5, 'max_depth': 30, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.640 (std: 0.002)\n",
      "Parameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 15, 'max_depth': 30, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n",
      "Best Performing Models are : None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Defining parameters of random forest\n",
    "parameters={'n_estimators':[10,50,100,300,500],\n",
    "            'max_features':[5,10,15,20],\n",
    "            'max_depth':[3,5,10,20,30,None],\n",
    "            'min_samples_split':[2,5,10,15,20],\n",
    "            'min_samples_leaf':[1,5,10,15,20],\n",
    "            'criterion':['entropy','gini'],\n",
    "            'bootstrap':[True,False] \n",
    "           }\n",
    "# Total Combinations possible 5*4*6*5*5*2*2=120000\n",
    "\n",
    "# Defining class\n",
    "clf=RandomForestClassifier(verbose=1,n_jobs=-1)\n",
    "\n",
    "# Searching 20 random models from 3072 combinations\n",
    "# Best way is to execute all the combinations and then look for best. But in this computation effort is enormous\n",
    "n_iter_search=5\n",
    "random_search=RandomizedSearchCV(clf,param_distributions=parameters,n_iter=n_iter_search,scoring='roc_auc',cv=3,\n",
    "                                 return_train_score=True)\n",
    "random_search.fit(x_cd_train,y_cd_train)\n",
    "\n",
    "# Function for report generation\n",
    "def report(results,n_top=3):\n",
    "    for i in range(1,n_top+1):\n",
    "        candidates=np.flatnonzero(results['rank_test_score']==i)\n",
    "        for candidate in candidates:\n",
    "            print('Model with rank: {0}'.format(i))\n",
    "            print('Mean validation score: {0:.3f} (std: {1:.3f})'.format(\n",
    "            results['mean_test_score'][candidate],\n",
    "            results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "# Calling the function report to get top performing model... n=3\n",
    "print('Best Performing Models are :',report(random_search.cv_results_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 15,\n",
       " 'max_features': 10,\n",
       " 'max_depth': 30,\n",
       " 'criterion': 'gini',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model parameters\n",
    "random_search.cv_results_['params'][random_search.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "ROC AUC score for Random Forest model is 0.6227696026352453\n",
      "-------------------------------\n",
      "Accuracy Using Random Forest is  58.25 %\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Defining Class for above obtained parameter combinations\n",
    "rf=RandomForestClassifier(n_estimators=100,min_samples_split=5,max_depth=30,max_features=15,bootstrap=True,\n",
    "                         criterion='gini',min_samples_leaf=5,class_weight='balanced',verbose=1)\n",
    "# Fitting model to rain data\n",
    "rf.fit(x_cd_train,y_cd_train)\n",
    "\n",
    "# Prediction on test data\n",
    "p_rf=rf.predict_proba(x_cd_test)[:,1]\n",
    "\n",
    "# Performance metrics : ROC score\n",
    "print('-------------------------------')\n",
    "print('ROC AUC score for Random Forest model is', roc_auc_score(y_cd_test,p_rf))\n",
    "print('-------------------------------')\n",
    "# Performance metrics : Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "prf=rf.predict(x_cd_test)\n",
    "score1=accuracy_score(y_cd_test,prf)\n",
    "print('Accuracy Using Random Forest is ', round(score1*100,2),'%')\n",
    "print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature day_diff (0.176751)\n",
      "2. feature Company_response_to_consumer_Closed with explanation (0.050136)\n",
      "3. feature Submitted_via_Web (0.042918)\n",
      "4. feature Company_response_to_consumer_Closed with non-monetary relief (0.042771)\n",
      "5. feature Company_response_to_consumer_Closed with monetary relief (0.036148)\n",
      "6. feature Tags (0.028402)\n",
      "7. feature State_CA (0.022186)\n",
      "8. feature State_FL (0.019874)\n",
      "9. feature State_TX (0.019250)\n",
      "10. feature State_NY (0.017792)\n",
      "11. feature Product_Mortgage (0.017400)\n",
      "12. feature Company_Bank_of_America (0.017059)\n",
      "13. feature Company_public_response_Company chooses not to provide a public response (0.016508)\n",
      "14. feature Submitted_via_Referral (0.016458)\n",
      "15. feature Issue_Incorrect_information_on_credit_report (0.015783)\n",
      "16. feature Product_Debt collection (0.015353)\n",
      "17. feature Consumer_consent_provided_Consent_not_provided (0.013815)\n",
      "18. feature State_GA (0.013736)\n",
      "19. feature State_NJ (0.013626)\n",
      "20. feature Company_public_response_Company has responded to the consumer and the CFPB and chooses not to provide a public response (0.013448)\n",
      "21. feature Company_Wells_Fargo_&_Company (0.013345)\n",
      "22. feature Company_JPMorgan_Chase_&_Co. (0.013252)\n",
      "23. feature Submitted_via_Postal mail (0.013047)\n",
      "24. feature State_IL (0.012619)\n",
      "25. feature Company_response_to_consumer_Closed without relief (0.012608)\n",
      "26. feature State_VA (0.012511)\n",
      "27. feature State_PA (0.012258)\n",
      "28. feature State_MD (0.012122)\n",
      "29. feature Company_Citibank (0.011831)\n",
      "30. feature Issue_Communication_tactics (0.011697)\n",
      "31. feature State_OH (0.011271)\n",
      "32. feature Issue_Loan_modification_collection_foreclosure (0.011245)\n",
      "33. feature Company_Experian (0.010870)\n",
      "34. feature State_MI (0.010576)\n",
      "35. feature State_WA (0.010558)\n",
      "36. feature State_NC (0.010556)\n",
      "37. feature Submitted_via_Phone (0.010387)\n",
      "38. feature State_AZ (0.009827)\n",
      "39. feature Issue_Loan_servicing__payments__escrow_account (0.009435)\n",
      "40. feature Consumer_consent_provided_Consent_provided (0.009193)\n",
      "41. feature Product_Credit reporting (0.009159)\n",
      "42. feature Company_public_response_Company believes it acted appropriately as authorized by contract or law (0.008906)\n",
      "43. feature Company_Capital_One (0.008553)\n",
      "44. feature Issue_Cont'd_attempts_collect_debt_not_owed (0.008326)\n",
      "45. feature Sub-product (0.007650)\n",
      "46. feature Company_Equifax (0.007572)\n",
      "47. feature Issue_Account_opening__closing__or_management (0.007438)\n",
      "48. feature Product_Credit card (0.007335)\n",
      "49. feature Consumer_complaint_narrative (0.007282)\n",
      "50. feature Timely_response (0.006898)\n",
      "51. feature Issue_Disclosure_verification_of_debt (0.006837)\n",
      "52. feature Issue_Credit_reporting_company's_investigation (0.006579)\n",
      "53. feature Company_Ocwen (0.006381)\n",
      "54. feature Company_TransUnion_Intermediate_Holdings__Inc. (0.006365)\n",
      "55. feature Submitted_via_Fax (0.005677)\n",
      "56. feature Issue_Deposits_and_withdrawals (0.005540)\n",
      "57. feature Product_Consumer Loan (0.005536)\n",
      "58. feature Issue_Billing_disputes (0.005535)\n",
      "59. feature Issue_Application__originator__mortgage_broker (0.005462)\n",
      "60. feature Product_Student loan (0.004974)\n",
      "61. feature Product_Money transfers (0.004601)\n",
      "62. feature Company_response_to_consumer_Closed with relief (0.004578)\n",
      "63. feature Consumer_consent_provided_Other (0.002957)\n",
      "64. feature Product_Payday loan (0.002898)\n",
      "65. feature Product_Prepaid card (0.002234)\n",
      "66. feature Company_public_response_Company believes the complaint is the result of a misunderstanding (0.001500)\n",
      "67. feature Company_public_response_Company disputes the facts presented in the complaint (0.001486)\n",
      "68. feature Company_public_response_Company believes complaint is the result of an isolated error (0.001201)\n",
      "69. feature Company_public_response_Company can't verify or dispute the facts in the complaint (0.000871)\n",
      "70. feature Company_public_response_Company believes complaint represents an opportunity for improvement to better serve consumers (0.000632)\n",
      "71. feature Product_Other financial service (0.000418)\n",
      "72. feature Product_Virtual currency (0.000000)\n",
      "73. feature Company_response_to_consumer_Untimely response (0.000000)\n",
      "74. feature Company_public_response_Company believes complaint relates to a discontinued policy or procedure (0.000000)\n",
      "75. feature Consumer_consent_provided_Consent_withdrawn (0.000000)\n"
     ]
    }
   ],
   "source": [
    "# Important features Ranking\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(x_cd_train.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, list(x_cd_train.columns)[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed:  2.5min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:  2.7min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  15 | elapsed:  2.9min remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:  3.4min remaining:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  15 | elapsed:  3.7min remaining:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  4.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.788 (std: 0.000)\n",
      "Parameters: {'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10, 15, 20), 'activation': 'tanh'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.788 (std: 0.000)\n",
      "Parameters: {'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (20, 10), 'activation': 'identity'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.788 (std: 0.000)\n",
      "Parameters: {'learning_rate_init': 0.1, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10, 15, 20), 'activation': 'tanh'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.788 (std: 0.000)\n",
      "Parameters: {'learning_rate_init': 0.001, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (20, 15, 10), 'activation': 'logistic'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.788 (std: 0.000)\n",
      "Parameters: {'learning_rate_init': 0.01, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10, 15), 'activation': 'identity'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV,KFold\n",
    "\n",
    "parameters={'hidden_layer_sizes':[(10,5),(5,10),(15,10),(10,15),(20,10),(5,10,15),(15,10,5),(20,15,10),(10,15,20)],\n",
    "           'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "           'learning_rate_init':[0.01,0.1,0.001],\n",
    "           'activation':['identity', 'logistic', 'tanh', 'relu']}\n",
    "\n",
    "NNclf=MLPClassifier()\n",
    "rsv=RandomizedSearchCV(NNclf,n_iter=5,cv=3,param_distributions=parameters,n_jobs=-1,verbose=20)\n",
    "rsv.fit(x_cd_train,y_cd_train)\n",
    "\n",
    "\n",
    "# Function for report generation\n",
    "def report(results,n_top=3):\n",
    "    for i in range(1,n_top+1):\n",
    "        candidates=np.flatnonzero(results['rank_test_score']==i)\n",
    "        for candidate in candidates:\n",
    "            print('Model with rank: {0}'.format(i))\n",
    "            print('Mean validation score: {0:.3f} (std: {1:.3f})'.format(\n",
    "            results['mean_test_score'][candidate],\n",
    "            results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "# Calling the function report to get top performing model... n=3\n",
    "report(rsv.cv_results_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6219847913404667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNclf=MLPClassifier(hidden_layer_sizes=(10,15,20),learning_rate='adaptive',activation='tanh',learning_rate_init=0.01)\n",
    "NNclf.fit(x_cd_train,y_cd_train)\n",
    "pred_test=NNclf.predict_proba(x_cd_test)[:,1]\n",
    "roc_auc_score(y_cd_test,pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost || XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_train.reset_index(drop=True,inplace=True)\n",
    "test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cd_train=cd_train.drop('Consumer_disputed',axis=1)\n",
    "y_cd_train=cd_train['Consumer_disputed']\n",
    "x_cd_test=cd_test.drop('Consumer_disputed',axis=1)\n",
    "y_cd_test=cd_test['Consumer_disputed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 73.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "          fit_params=None, iid=True, n_iter=5, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [50, 100, 200, 500, 700], 'learning_rate': [0.01, 0.1, 1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_clf=tree.DecisionTreeClassifier(max_leaf_nodes=10,class_weight='balanced')\n",
    "adb_params={'n_estimators':[50,100,200,500,700],\n",
    "           'learning_rate': [0.01,.1,1]\n",
    "           }\n",
    "adb=AdaBoostClassifier(base_estimator=base_clf)\n",
    "\n",
    "n_iter_search=5\n",
    "random_search=RandomizedSearchCV(adb,param_distributions=adb_params,n_iter=n_iter_search,scoring='roc_auc',cv=3,\n",
    "                                 return_train_score=True,verbose=2,n_jobs=-1)\n",
    "random_search.fit(x_cd_train,y_cd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.620 (std: 0.001)\n",
      "Parameters: {'n_estimators': 500, 'learning_rate': 0.01}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.620 (std: 0.002)\n",
      "Parameters: {'n_estimators': 50, 'learning_rate': 1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.618 (std: 0.002)\n",
      "Parameters: {'n_estimators': 100, 'learning_rate': 1}\n",
      "\n",
      "Best Performing Models are : None\n"
     ]
    }
   ],
   "source": [
    "def report(results,n_top=3):\n",
    "    for i in range(1,n_top+1):\n",
    "        candidates=np.flatnonzero(results['rank_test_score']==i)\n",
    "        for candidate in candidates:\n",
    "            print('Model with rank: {0}'.format(i))\n",
    "            print('Mean validation score: {0:.3f} (std: {1:.3f})'.format(\n",
    "            results['mean_test_score'][candidate],\n",
    "            results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "# Calling the function report to get top performing model... n=3\n",
    "print('Best Performing Models are :',report(random_search.cv_results_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clf=tree.DecisionTreeClassifier(max_leaf_nodes=10,class_weight='balanced')\n",
    "adb_best=AdaBoostClassifier(base_estimator=base_clf,learning_rate=0.01,n_estimators=500)\n",
    "adb_best.fit(x_cd_train,y_cd_train)\n",
    "p=adb_best.predict_proba(x_cd_test)[:,1]\n",
    "roc_auc_score(y_cd_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.620490048740005"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_cd_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \n",
    "              \"max_depth\": [3,4,5,6,7],\n",
    "              \"learning_rate\":[0.01,0.05,0.1,0.3,0.5],\n",
    "    \"min_child_weight\":[4,5,6],\n",
    "              \"subsample\":[i/10.0 for i in range(6,10)],\n",
    " \"colsample_bytree\":[i/10.0 for i in range(6,10)],\n",
    "               \"reg_alpha\":[1e-5, 1e-2, 0.1, 1, 100],\n",
    "              \"gamma\":[i/10.0 for i in range(0,5)],\n",
    "    \"n_estimators\":[100,500,700,1000],\n",
    "    'scale_pos_weight':[2,3,4,5,6,7,8,9]\n",
    "    \n",
    "              }\n",
    "clf=XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "n_iter=10\n",
    "\n",
    "random_search=RandomizedSearchCV(clf,n_jobs=-1,verbose=20,cv=3,n_iter=n_iter,scoring='roc_auc',\n",
    "                                 param_distributions=param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed: 39.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 81.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 88.0min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 95.4min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 96.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 98.3min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 104.9min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 112.9min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 113.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 115.5min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 123.7min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 131.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  30 | elapsed: 140.2min remaining: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 146.3min remaining: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 153.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'max_depth': [3, 4, 5, 6, 7], 'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5], 'min_child_weight': [4, 5, 6], 'subsample': [0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9], 'reg_alpha': [1e-05, 0.01, 0.1, 1, 100], 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4], 'n_estimators': [100, 500, 700, 1000], 'scale_pos_weight': [2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_cd_train,y_cd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.626 (std: 0.001)\n",
      "Parameters: {'subsample': 0.6, 'scale_pos_weight': 6, 'reg_alpha': 0.1, 'n_estimators': 500, 'min_child_weight': 6, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.626 (std: 0.002)\n",
      "Parameters: {'subsample': 0.9, 'scale_pos_weight': 3, 'reg_alpha': 100, 'n_estimators': 1000, 'min_child_weight': 4, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.4, 'colsample_bytree': 0.8}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.626 (std: 0.001)\n",
      "Parameters: {'subsample': 0.7, 'scale_pos_weight': 2, 'reg_alpha': 1, 'n_estimators': 500, 'min_child_weight': 6, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def report(results,n_top=3):\n",
    "    for i in range(1,n_top+1):\n",
    "        candidates=np.flatnonzero(results['rank_test_score']==i)\n",
    "        for candidate in candidates:\n",
    "            print('Model with rank: {0}'.format(i))\n",
    "            print('Mean validation score: {0:.3f} (std: {1:.3f})'.format(\n",
    "            results['mean_test_score'][candidate],\n",
    "            results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "report(random_search.cv_results_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best=XGBClassifier(subsample=0.6,scale_pos_weight=6,reg_alpha=0.1,n_estimators=500,min_child_weight=6,\n",
    "                       max_depth=4,learning_rate=0.05,gamma=0.1,colsample_bytree=0.8\n",
    "                      )\n",
    "xgb_best.fit(x_cd_train,y_cd_train)\n",
    "\n",
    "p=xgb_best.predict_proba(x_cd_test)[:,1]\n",
    "roc_auc_score(y_cd_test,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5985766087482918"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.DataFrame()\n",
    "x_train['g1']=logreg.predict_proba(x_cd_train)[:,1]\n",
    "x_train['g2']=dtree.predict_proba(x_cd_train)[:,1]\n",
    "x_train['g3']=rf.predict_proba(x_cd_train)[:,1]\n",
    "x_train['g4']=NNclf.predict_proba(x_cd_train)[:,1]\n",
    "\n",
    "LR=LogisticRegression(class_weight='balanced')\n",
    "LR.fit(x_train,y_cd_train)\n",
    "\n",
    "x_test=pd.DataFrame()\n",
    "x_test['g1']=logreg.predict_proba(x_cd_test)[:,1]\n",
    "x_test['g2']=dtree.predict_proba(x_cd_test)[:,1]\n",
    "x_test['g3']=rf.predict_proba(x_cd_test)[:,1]\n",
    "x_test['g4']=NNclf.predict_proba(x_cd_test)[:,1]\n",
    "\n",
    "p=LR.predict_proba(x_test)[:,1]\n",
    "roc_auc_score(y_cd_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test=r\"I:\\data scientist using python\\project1\\P1 Data\\Consumer_Complaints_test_share.csv\"\n",
    "test1=pd.read_csv(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     119580\n",
       "Yes        26\n",
       "Name: Consumer disputed?, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.DataFrame({'Complaint ID':test1['Complaint ID']})\n",
    "submission['Consumer disputed?']=NNclf.predict(test)\n",
    "submission['Consumer disputed?']=submission['Consumer disputed?'].map({1:'Yes',0:'No'})\n",
    "submission['Consumer disputed?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No     65206\n",
       "Yes    54400\n",
       "Name: Consumer disputed?, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.DataFrame({'Complaint ID':test1['Complaint ID']})\n",
    "submission['Consumer disputed?']=rf.predict(test)\n",
    "submission['Consumer disputed?']=submission['Consumer disputed?'].map({1:'Yes',0:'No'})\n",
    "submission['Consumer disputed?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75397\n",
       "1    20288\n",
       "Name: Consumer_disputed, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cd_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     61532\n",
       "Yes    58074\n",
       "Name: Consumer disputed?, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.DataFrame({'Complaint ID':test1['Complaint ID']})\n",
    "submission['Consumer disputed?']=logreg.predict(test)\n",
    "submission['Consumer disputed?']=submission['Consumer disputed?'].map({1:'Yes',0:'No'})\n",
    "submission['Consumer disputed?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('submission.xlsx')\n",
    "submission.to_excel(writer,index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
